
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 

from sklearn import linear_model
from sklearn.linear_model import LinearRegression 
lm = LinearRegression()
from sklearn import feature_selection
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import neighbors

import statsmodels.api as sm

original_cancer = pd.read_csv("~/Downloads/cancer.csv")
cancer = pd.read_csv("~/Downloads/cancer.csv")
dummy_cancer = pd.get_dummies(data = cancer, drop_first=True) #adding dummy variables for categorical variable #region
# print(dummy_cancer.columns)

_X = dummy_cancer[['avgDeathsPerYear', 'incidenceRate', 'medIncome','povertyPercent', 'studyPerCap', 'MedianAge', 'AvgHouseholdSize','PercentMarried', 'PctPrivateCoverage', 'PctPublicCoverage','BirthRate', 'region_Northeast', 'region_South','region_West']]
_y = dummy_cancer['TARGET_deathRate']

#Splitting data into training and test sets
#splitting training and Test data in 1:3 ratio
X_train_valid , X_test, y_train_valid, y_test = train_test_split(_X,_y, test_size = 0.25, random_state = 7283) 
# further diving data 
#splitting training_Validation where 20% is validation data 
#This is a 2:1 split not 4:1. 
X_train, X_valid , y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 1/3, random_state = 7283)

X = cancer.copy()
del X['TARGET_deathRate']


# #Q1: Linear Regression : 24 pts
#A.
#Model Diagnosis
X_int = sm.add_constant(_X)
linreg = sm.OLS(_y, X_int).fit()
print(linreg.summary())

# Analysis 
# - Rsq = 0.473
# - Not significant values: povertyPercent, studyPerCap, AvgHouseholdSize, PercentMarried p-values greater than 0.05
# - Negative Coefficients - AvgDeathsPerYear, medIncome, studyPerCap, MedianAge,PercentMarried, PctPrivateCoverage,BirthRate negatively affect the TargetDeathRate, i.e., the number of deaths caused decline by increase in values of these variables
# - Positive coefficients incidenceRate, povertyPercent, AvgHouseholdSize, PctPublicCoverage are positive, i.e., Increase in value of these variables cause increase in death rate.
# - Other parameters being the same, regions with highest death rate due to cancer is South, followerd by Midwest (baseline at 0), followed by Northeast and lastly West. 
#Not sure if this is well-supported. 
#Lack interpretation Ã²f coefficients
#B.
#Model Assessment 
#Lacking linear relationship plots:
# plt.scatter(linreg.fittedvalues, linreg.resid) #Residual vs fitted value plot
# plt.xlabel('Fitted Values')
# plt.ylabel('Residuals')
# plt.title('Residuals vs Fitted Values')
# plt.show()
# The residual plot definitely looks like an evenly distributed blob with a few outliers. Since it is evenly distributed around the axis, linear Regression looks like a good model. However since our Rsq. values are pretty low & since the outliers are affecting the visualization, removing the outliers will give a better sense on the model.

# # QQ Plot
# qqplot = sm.qqplot(linreg.resid)
# plt.show()
#plot is a pretty straight line with some deviations at the end which are pretty normal given we have observed the outliers in the earlier residual plot as well. Looks like an acceptable model

#C.Report MSE value on the test set. 

linreg = LinearRegression() #fitting LinearRegression model on training Data

linreg.fit(X_train_valid,y_train_valid)
y_test_pred = linreg.predict(X_test)
MSE_test = np.mean((y_test - y_test_pred)**2)

print("MSR for linear regression is ", MSE_test)

#Analysis
# MSE value on test set is 432.76

# Q2.A Lasso: 24/25

# # #Scaling the data
scaler = StandardScaler() # Instantiate
scaler.fit(X_train) # Fit the data
X_train = pd.DataFrame(scaler.transform(X_train)) #transform X data
X_valid = pd.DataFrame(scaler.transform(X_valid))
X_train.columns = _X.columns.values
X_valid.columns = _X.columns.values

alphas = np.logspace(-10, 10, 21) #choosing range of 21 alpha values 

Validation_Scores = []
for a in alphas:
    lm_lasso = linear_model.Lasso(alpha=a)
    lm_lasso.fit(X_train, y_train) # Fit lasso model on training set
    Validation_Scores.append(metrics.mean_squared_error(lm_lasso.predict(X_valid), y_valid)) #Evaluating model on validation set

#Find minimum validation error and the corresponding lambda value
print("Min validation error for Lasso ", min(Validation_Scores))
minalpha = alphas[np.argmin(Validation_Scores)]
print("Min Alpha for Lasso", minalpha)

# Lambda value = 0.1 and min testing_score (MSE) is 471.52
# test MSE for Lasso is a more than the MSE test for Regression. 

# #Scale data (use the train_valid set to fit, then transform both the train_valid set and test set)
#You are scaling the data again. The value of alpha might not be the same. 
scaler.fit(X_train_valid) # Fit the data
X_train_valid = pd.DataFrame(scaler.transform(X_train_valid)) # Transform the data
X_test = pd.DataFrame(scaler.transform(X_test))
X_train_valid.columns = _X.columns.values
X_test.columns = _X.columns.values

# # Refit model with train + validation set, perform prediction on test set
lm_lasso = linear_model.Lasso(alpha=minalpha)
lm_lasso.fit(X_train_valid, y_train_valid) # Fit model on training set
Validation_Scores_alpha = metrics.mean_squared_error(lm_lasso.predict(X_test), y_test)

print("Lasso validation score on test data", Validation_Scores_alpha)

# # #
# Analysis:
# MSE is 430 which is better than both the MSE values calculated above. So this is a good model fit for the data

print("Lasso coeffs")
print(pd.DataFrame(zip(lm_lasso.coef_, X_train_valid.columns.values)))

#Analysis
# - The coefficients for all variables has been normalised, esp for categorical dummy variables which had really high coeff. values. 
# - Coeff for incidenceRate have increased significantly and stands out among all others. 
# - Comparing with Linear Regression, the coefficients for 4 region dummy variables have pretty much the same interpretation. 


# Q2.B Ridge
#Same problem with tuning and scaling process: 25/25

# alphas = np.logspace(-10, 10, 21)

# Valid_Scores = []
# for a in alphas:
#     lm_ridge = linear_model.Ridge(alpha=a)
#     lm_ridge.fit(X_train, y_train) # Fit model on training set
#     Valid_Scores.append(metrics.mean_squared_error(lm_ridge.predict(X_valid), y_valid)) # Evaluate model on validation set

# # # # #Find minimum validation error and the corresponding lambda value
# print("Min validation error for Ridge", min(Valid_Scores))
# minalpha = alphas[np.argmin(Valid_Scores)]
# print("Min Alpha for Ridge", minalpha)

# #Analysis
# # #Lambda value is 1.0 at lowest MSE value of 472.18

# # # Refit model with minalpha on train + validation set, perform prediction on test set
# lm_ridge = linear_model.Ridge(alpha = minalpha)
# lm_ridge.fit(X_train_valid, y_train_valid)
# validation_score = metrics.mean_squared_error(lm_ridge.predict(X_test), y_test)
# print("Ridge validation score on test data", validation_score)

# # MSE values of Ridge Regression is 432 less than Linear(432) and Lasso(430). 

# print("Ridge coeffs")
# print(pd.DataFrame(zip(lm_ridge.coef_, X.columns.values))) #printing variable name and their coef values together

# ##Analysis
# #the coefficient values are very similar to the Lasso model and different from Linear Regression model above. While the variables with negative coefficients have been the same, the negative values have changed and are normalised. 
# #no variables have been dropped. 

# #Q3. KNN
# #Same problem with the tuning process. 23/25
# # Creating a categorical response variable based on TARGET_deathRate
# #The number of groups K could be different.
# dummy_cancer['tdr_category'] = np.array(pd.qcut(dummy_cancer['TARGET_deathRate'], q = [0, .33, .67, 1], labels = ['low','medium','high']))
# print(dummy_cancer.groupby('tdr_category').size())

# _X = dummy_cancer[['avgDeathsPerYear', 'incidenceRate', 'medIncome','povertyPercent', 'studyPerCap', 'MedianAge', 'AvgHouseholdSize','PercentMarried', 'PctPrivateCoverage', 'PctPublicCoverage','BirthRate', 'region_Northeast', 'region_South','region_West']]
# _y = dummy_cancer['tdr_category']

# # # Splitting data into train_valid and test set 
# X_train_valid , X_test, y_train_valid, y_test = train_test_split(_X,_y, test_size = 0.25, random_state = 7283) #splitting training and Test data in 1:3 ratio
# # Further splitting the data into train and valid set
# X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.37, random_state = 7283) #further splitting into train and validation

# # #Scaling the data using stdScalar()
# scaler = StandardScaler()
# scaler.fit(X_train) # Fit
# X_train = scaler.transform(X_train) #Transform
# X_valid = scaler.transform(X_valid)

# valid_misclf = []
# for k in range(1, 11):
#     knn = neighbors.KNeighborsClassifier(n_neighbors = k)
#     knn.fit(X_train, y_train)
    
#     y_hat = knn.predict(X_valid)
#     valid_misclf.append(np.mean(y_hat != y_valid))


# import matplotlib.pyplot as plt
# plt.plot(range(1,11), valid_misclf)
# plt.show()

# bestK = np.argmin(valid_misclf) + 1
# print(bestK)
# print(valid_misclf[bestK-1])

# accuracy_score1 = knn.score(X_valid, y_valid)
# print('Accuracy score of KNN is',accuracy_score1)

# # #As seen in the graph, for range (1, 11) the best K is 4 at misclassification of 40.86% which says that about 60% predictions are correct. Not a good number. 
# ##Accuracy score is 58.6 
# # # #### Train algorithm with the optimal K found above

# scaler.fit(X_train_valid)
# X_train_valid = pd.DataFrame(scaler.transform(X_train_valid))
# X_test = pd.DataFrame(scaler.transform(X_test))
# X_train_valid.columns = _X.columns.values


# knn = neighbors.KNeighborsClassifier(n_neighbors = bestK, weights = 'uniform')
# knn.fit(X_train_valid, y_train_valid)
# yhat = knn.predict(X_test)
# misclf = np.mean(yhat != y_test)
# # # print(misclf) 

# accuracy_score2 = knn.score(X_test, y_test)
# print(accuracy_score2)

# # Misclassification percentage increase a bit from 40.8% to 44.5 and accuracy score is 55.4%. 
